{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlHreAuYztFjR4N4wKRR9D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parwinderau/DataspaceConnector/blob/main/Simple_JSON_Synthetic_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiyGruV4mS9g",
        "outputId": "44c610b4-372c-4b06-8d3f-2cbe9360d095"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-27.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Downloading Faker-27.0.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m1.4/1.8 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-27.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a25d7HRmNgH",
        "outputId": "768b8366-1d0a-458a-e57d-1629e3644c58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"device_id\": \"baeb342d-d9e8-4833-ae1e-d437c9c133ab\",\n",
            "    \"timestamp\": \"2018-10-25T18:49:49.894426\",\n",
            "    \"measurements\": {\n",
            "      \"temperature\": -0.9168523885050668,\n",
            "      \"humidity\": 15.577727734748246\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"device_id\": \"10cab8a2-9ea2-4c8d-9389-e80d8a892fdc\",\n",
            "    \"timestamp\": \"1977-04-29T16:44:09.032658\",\n",
            "    \"measurements\": {\n",
            "      \"temperature\": 17.40642111889551,\n",
            "      \"humidity\": 57.87882101785955\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"device_id\": \"eeccb19f-cec8-4d5b-996b-213b880a08b7\",\n",
            "    \"timestamp\": \"2017-12-12T04:02:19.651435\",\n",
            "    \"measurements\": {\n",
            "      \"temperature\": 23.046873212378458,\n",
            "      \"humidity\": 17.822500057269934\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"device_id\": \"22d7965a-e07a-4faf-9347-363f9c1e7867\",\n",
            "    \"timestamp\": \"1979-10-10T23:26:13.392379\",\n",
            "    \"measurements\": {\n",
            "      \"temperature\": 22.538488845879005,\n",
            "      \"humidity\": 42.10645209994575\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"sensor_id\": \"d34495a3-5a26-4e51-a871-bfd85d206633\",\n",
            "    \"time\": \"2010-04-28T01:57:31.748625\",\n",
            "    \"readings\": {\n",
            "      \"temp\": 46.60438254407449,\n",
            "      \"humid\": 89.62870669711401\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "from faker import Faker\n",
        "from copy import deepcopy\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "# Base template for generating synthetic JSON data\n",
        "base_template = {\n",
        "    \"device_id\": None,\n",
        "    \"timestamp\": None,\n",
        "    \"measurements\": {\n",
        "        \"temperature\": None,\n",
        "        \"humidity\": None\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to generate synthetic data\n",
        "def generate_data(template, structure_variation=True, semantic_variation=True):\n",
        "    data = deepcopy(template)\n",
        "\n",
        "    # Semantically same information but structurally different\n",
        "    if structure_variation and not semantic_variation:\n",
        "        data = {key: data[key] for key in reversed(list(data.keys()))}  # Reverse the order of keys\n",
        "\n",
        "    # Structurally same but semantically different\n",
        "    elif not structure_variation and semantic_variation:\n",
        "        data[\"device_id\"] = fake.uuid4()\n",
        "        data[\"timestamp\"] = fake.date_time().isoformat()\n",
        "        data[\"measurements\"][\"temperature\"] = random.uniform(-10, 50)  # Different but valid temperature range\n",
        "        data[\"measurements\"][\"humidity\"] = random.uniform(10, 90)  # Different but valid humidity range\n",
        "\n",
        "    # Structural and semantically both different\n",
        "    elif structure_variation and semantic_variation:\n",
        "        data[\"sensor_id\"] = data.pop(\"device_id\")  # Change the key name\n",
        "        data[\"time\"] = data.pop(\"timestamp\")  # Change the key name\n",
        "        data[\"readings\"] = data.pop(\"measurements\")  # Change the key name\n",
        "        data[\"readings\"][\"temp\"] = data[\"readings\"].pop(\"temperature\")  # Change the key name\n",
        "        data[\"readings\"][\"humid\"] = data[\"readings\"].pop(\"humidity\")  # Change the key name\n",
        "        data[\"sensor_id\"] = fake.uuid4()\n",
        "        data[\"time\"] = fake.date_time().isoformat()\n",
        "        data[\"readings\"][\"temp\"] = random.uniform(-10, 50)\n",
        "        data[\"readings\"][\"humid\"] = random.uniform(10, 90)\n",
        "\n",
        "    # Structural and semantically both same\n",
        "    else:\n",
        "        data[\"device_id\"] = fake.uuid4()\n",
        "        data[\"timestamp\"] = fake.date_time().isoformat()\n",
        "        data[\"measurements\"][\"temperature\"] = random.uniform(15, 30)\n",
        "        data[\"measurements\"][\"humidity\"] = random.uniform(30, 70)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Generate a dataset with varying conditions\n",
        "def generate_synthetic_dataset(num_samples=10):\n",
        "    dataset = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        condition = random.choice([\n",
        "            'structure_diff_semantic_same',\n",
        "            'structure_same_semantic_diff',\n",
        "            'structure_semantic_both_diff',\n",
        "            'structure_semantic_both_same'\n",
        "        ])\n",
        "\n",
        "        if condition == 'structure_diff_semantic_same':\n",
        "            data = generate_data(base_template, structure_variation=True, semantic_variation=False)\n",
        "\n",
        "        elif condition == 'structure_same_semantic_diff':\n",
        "            data = generate_data(base_template, structure_variation=False, semantic_variation=True)\n",
        "\n",
        "        elif condition == 'structure_semantic_both_diff':\n",
        "            data = generate_data(base_template, structure_variation=True, semantic_variation=True)\n",
        "\n",
        "        else:  # 'structure_semantic_both_same'\n",
        "            data = generate_data(base_template, structure_variation=False, semantic_variation=False)\n",
        "\n",
        "        dataset.append(data)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Generate and display synthetic data\n",
        "synthetic_data = generate_synthetic_dataset(5)\n",
        "print(json.dumps(synthetic_data, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is for NLP based JSON data generator for IoT domain\n",
        "import json\n",
        "import random\n",
        "from faker import Faker\n",
        "from copy import deepcopy\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import download\n",
        "\n",
        "# Download necessary NLTK data\n",
        "download('wordnet')\n",
        "download('omw-1.4')\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "# Function to get synonyms from WordNet\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "    return list(synonyms)\n",
        "\n",
        "# Generate variations of terms used in JSON keys\n",
        "term_variations = {\n",
        "    \"device_id\": get_synonyms(\"device\")[:5] + [\"sensor_id\", \"equipment_id\", \"machine_id\"],\n",
        "    \"timestamp\": get_synonyms(\"timestamp\")[:5] + [\"time\", \"datetime\", \"log_time\"],\n",
        "    \"measurements\": get_synonyms(\"measurement\")[:5] + [\"readings\", \"data\", \"values\"],\n",
        "    \"temperature\": get_synonyms(\"temperature\")[:5] + [\"temp\", \"heat\", \"thermal\"],\n",
        "    \"humidity\": get_synonyms(\"humidity\")[:5] + [\"moisture\", \"dampness\", \"humid\"],\n",
        "}\n",
        "\n",
        "# Base template for generating synthetic JSON data\n",
        "base_template = {\n",
        "    \"device_id\": None,\n",
        "    \"timestamp\": None,\n",
        "    \"measurements\": {\n",
        "        \"temperature\": None,\n",
        "        \"humidity\": None\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to generate synthetic data with NLP variations\n",
        "def generate_data(template, structure_variation=True, semantic_variation=True):\n",
        "    data = deepcopy(template)\n",
        "\n",
        "    # Apply term variations\n",
        "    def apply_variations(d):\n",
        "        for key in list(d.keys()):\n",
        "            if isinstance(d[key], dict):\n",
        "                apply_variations(d[key])\n",
        "            new_key = random.choice(term_variations.get(key, [key]))\n",
        "            if new_key != key:\n",
        "                d[new_key] = d.pop(key)\n",
        "\n",
        "    if structure_variation:\n",
        "        apply_variations(data)\n",
        "\n",
        "    # Semantically same but structurally different\n",
        "    if structure_variation and not semantic_variation:\n",
        "        pass  # Already handled by apply_variations\n",
        "\n",
        "    # Structurally same but semantically different\n",
        "    elif not structure_variation and semantic_variation:\n",
        "        data[\"device_id\"] = fake.uuid4()\n",
        "        data[\"timestamp\"] = fake.date_time().isoformat()\n",
        "        data[\"measurements\"][\"temperature\"] = random.uniform(-10, 50)\n",
        "        data[\"measurements\"][\"humidity\"] = random.uniform(10, 90)\n",
        "\n",
        "    # Structural and semantically both different\n",
        "    elif structure_variation and semantic_variation:\n",
        "        data[\"device_id\"] = fake.uuid4()\n",
        "        data[\"timestamp\"] = fake.date_time().isoformat()\n",
        "        data[\"measurements\"][\"temperature\"] = random.uniform(-10, 50)\n",
        "        data[\"measurements\"][\"humidity\"] = random.uniform(10, 90)\n",
        "\n",
        "    # Structural and semantically both same\n",
        "    else:\n",
        "        data[\"device_id\"] = fake.uuid4()\n",
        "        data[\"timestamp\"] = fake.date_time().isoformat()\n",
        "        data[\"measurements\"][\"temperature\"] = random.uniform(15, 30)\n",
        "        data[\"measurements\"][\"humidity\"] = random.uniform(30, 70)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Generate a dataset with varying conditions\n",
        "def generate_synthetic_dataset(num_samples=10):\n",
        "    dataset = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        condition = random.choice([\n",
        "            'structure_diff_semantic_same',\n",
        "            'structure_same_semantic_diff',\n",
        "            'structure_semantic_both_diff',\n",
        "            'structure_semantic_both_same'\n",
        "        ])\n",
        "\n",
        "        if condition == 'structure_diff_semantic_same':\n",
        "            data = generate_data(base_template, structure_variation=True, semantic_variation=False)\n",
        "\n",
        "        elif condition == 'structure_same_semantic_diff':\n",
        "            data = generate_data(base_template, structure_variation=False, semantic_variation=True)\n",
        "\n",
        "        elif condition == 'structure_semantic_both_diff':\n",
        "            data = generate_data(base_template, structure_variation=True, semantic_variation=True)\n",
        "\n",
        "        else:  # 'structure_semantic_both_same'\n",
        "            data = generate_data(base_template, structure_variation=False, semantic_variation=False)\n",
        "\n",
        "        dataset.append(data)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Generate and display synthetic data\n",
        "synthetic_data = generate_synthetic_dataset(5)\n",
        "print(json.dumps(synthetic_data, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSKf7qLknbfp",
        "outputId": "c09b36ff-1b13-4d40-8839-972f6447a96c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"device_id\": \"f70f6a2f-9afb-4e4e-b062-2466476d0105\",\n",
            "    \"timestamp\": \"1995-05-12T08:43:15.351342\",\n",
            "    \"measurements\": {\n",
            "      \"temperature\": 21.205621152364852,\n",
            "      \"humidity\": 17.171543068727644\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"device\": null,\n",
            "    \"time\": null,\n",
            "    \"mensuration\": {\n",
            "      \"humidity\": null,\n",
            "      \"temp\": null\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"device_id\": \"20cccd6f-5904-4373-8b59-ebc5abc0ec9d\",\n",
            "    \"timestamp\": \"2002-10-23T02:30:10.833039\",\n",
            "    \"measurements\": {\n",
            "      \"temperature\": 24.250107522842594,\n",
            "      \"humidity\": 41.437023672510215\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"twist\": null,\n",
            "    \"time\": null,\n",
            "    \"measure\": {\n",
            "      \"temperature\": null,\n",
            "      \"humidity\": null\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"sensor_id\": null,\n",
            "    \"datetime\": null,\n",
            "    \"measuring\": {\n",
            "      \"temperature\": null,\n",
            "      \"humidness\": null\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}